# Reuse Server 

The Reuse Server is serverless. Its API is hosted in API Gateway and the requests are handled by AWS lambda functions. 

## ORM
Models are automatically generated by pg-generator.

The command is used to create models:
node_modules/pg-generator/lib/bin/pgen.js exec sequelize-template -h omr2.cx1ui78d21gz.us-west-2.rds.amazonaws.com -d drvr2071 -u xxx -p xxx -t model

## DB Migrations
To run migrations, you need a configuration file. A good place to put it is in config/migrations.json. Here's an example content:

{
    "development": {
        "username": "xxx",
        "password": "xxx",
        "database": "reuse",
        "host": "127.0.0.1",
        "dialect": "postgres"
    },
    "test": {
        "username": "xxx",
        "password": "xxx",
        "database": "reuse",
        "host": "127.0.0.1",
        "dialect": "postgres"
    },
    "production": {
        "username": "xxx",
        "password": "xxx",
        "database": "reuse",
        "host": "127.0.0.1",
        "dialect": "postgres"
    }
}

To run migrations, run:

    node_modules/.bin/sequelize db:migrate --config config/migrations.json

And to revert, run:

    node_modules/.bin/sequelize db:migrate:undo --config config/migrations.json

## Deployment

You should have the 'deployment' folder having all the required files with ./deploy.sh file
Paste the 'deployment' folder on root of the project and proceed further steps

To deploy just run the 'deploy.sh' script.

    Usage:
        AWS_DEFAULT_REGION=[AWSRegion] ./deploy.sh [SiteName] [StageName]

        SiteName is a string describing the site, which the service is deployed for.
        AWSRegion is a string describing the AWS region, which the service is deployed into.

        StageName is a string describing the stage. Currently it is used to create a S3 bucket for the database archive which is used by archive-db.
        AWS_DEFAULT_REGION=us-west-2 ./deploy.sh reuse dev

In order to deploy, the AWS cli must be installed and the AWS cli user must be a member of the AWS IAM group reuseServerDevelopers.
The easiest way to install the AWS CLI is to use pip, a package manager for Python that provides an easy way to install, upgrade,
and remove Python packages and their dependencies.
```shell
sudo apt install python-pip
```
to install pip and
```shell
sudo pip install awscli --upgrade
```
to install or upgrade AWS CLI system wide. If you prefer to install it locally you can add the --user option (make sure ~/.local/bin is in your path). Next step is to configure aws to give access to your account:
```shell
aws configure
```

## AWS permissions

Developers are NOT granted the entire set of permissions required to deploy the Reuse Server. Instead they are
granted permission to pass along those permissions to the CloudFormation service. This section describes steps that can
be taken by the administrator of the AWS account to setup this security system.

1. Create an IAM Role called 'reuseServerCloudFormationDeploymentRole' for CloudFormation with the permission to create all
the resources needed by the Reuse server. The file **reuseServerDeploymentPolicy** is a valid IAM policy document that can be
copied and pasted to create the policy from the AWS console. It grants permission to manage the resources needed by the
Reuse server (S3 buckets, lambda functions, API Gateway and IAM 
role/policy creation).
2. Create an IAM Group called 'reuseServerDevelopers' with permission to manage CloudFormation stacks and to pass along the
role created in step 1 to the CloudFormation service. The file **reuseServerDeveloperPolicy** is a valid IAM policy document
that can be copied and pasted to create the policy for this group on the AWS console.

For convenience these steps are automated in the **aws-setup-permission.sh** script. That script only needs to be run
once by an administrator of the AWS account. It does not take any arguments.

### AWS permissions maintenance

Three scripts are provided to update the AWS account permission for the Reuse server.

```shell
./aws-update-assume-role_policy.sh
Updates the role trust policy. Use after updating the file ./reuseServerCloudFormationDeploymentRole
```
```shell
./aws-update-deploy-policy.sh
Updates the deployment policy. Use when updating the file
./reuseServerDeploymentPolicy
```
```shell
./aws-update-dev-policy.sh
Update the dev policy. Use when updating the file
./reuseServerDeveloperPolicy
```

## Testing

To set up testing on your local machine you need to install SAM local and DynamoDB local. To install
SAM local it is best to use NPM:
```shell
npm install -g aws-sam-local@0.2.2
```
and verify that the installation worked:
```shell
sam --version
```
the version must be 0.2.2 since newer versions don't work with the CF template.

If you get a permission error when using npm (such as EACCES: permission denied), please see the
instructions on this [page](https://docs.npmjs.com/getting-started/fixing-npm-permissions) of the
NPM documentation. In order to use SAM local, you need to have docker installed on your machine.
You won't need to create any Docker container or image, SAM Local will do that automatically.

### SAM local

There are 2 features of SAM local that we use:

I. sam local start-api: This command spawns a local API Gateway in a Docker container on your machine.
The first time you run the command, it will pull images totalling roughly 1GB in size. The local API Gateway
listens on port 3000 by default, once it is running you can send request to it with any tool you like
(curl, postman, chrome, etc). Sample command:
```shell
AWS_REGION=us-west-2 sam local start-api -t sam-local-template.yaml -n config/environment-variables.json --parameter-values 'ParameterKey=SiteName,ParameterValue=test' -d 5858
```

The '-d 5858' option is only needed if you plan to step through the code in your IDE when debugging, in this case
you would have to attach to the process running on port 5858 (more on this below) AFTER you send the curl (or postman, or chrome, ...) command.

II. sam local invoke: This command lets you invoke your lambda functions locally (again using docker).
```shell
AWS_REGION=us-west-2 sam local invoke -t sam-template.yaml -n config/environment-variables.json --parameter-values 'ParameterKey=SiteName,ParameterValue=test' -e test/bookings.json -d 5858 LambdaApiPostBooking
```

NOTE: When SAM local pulls docker images to install on your local machine you will NOT see docker containers, just images. So you won't see any sort of lambda container when running _docker ps_. Docker containers are instantiated from the image each time a lambda is invoked. If you are fast enough (or if your lambda takes a long time to run) you can run _docker ps_ again while your lamdas are executing, you will now see the docker container hosting your lambda function.

### reuse Server Tests
There are 3 different ways the lambda functions are tested in this repository

1. Using SAM local start-api. Here we simply 'curl' a request to the
reuse Server running locally using its API. The local API Gateway
is responsible for generating the Lambda event and context and for
calling the lambda function. Note that the API Gateway is set up to
use Lambda Proxy Integration so it will post-process the response
from the lambda to transform it into a specific format before forwarding
it back to you.

2. Using SAM local invoke. Here we invoke lambdas directly and they
are run locally using docker. In this method we are responsible for
creating the Lambda event and context (the set of events used for the
tests are located in the test/events/ folder). Because API Gateway is
not involved we received the response from the lambda untransformed.

3. Using nodejs. Because lambda function are just nodejs code, it is
possible to just call them. This is very similar to method 2 since we
are responsible for creating the lambda events and receive the response
untransformed. The difference is that the AWS Lambda environment is not
created (for example when you define your lambda in the SAM template or
Cloud Formation template, you have to specify the maximum amount of memory
used and how long the lambda can run before timing out, etc.) Obviously
nodejs is not aware of those limits so no exception will be thrown if
any are violated.

Of the 3 methods, number 1 is the closest to a production environment
and number 3 is the worst model but is the easiest way to debug the
logic of the lambda functions. All 3 methods have values.

### IDE

To be able to step through code in your IDE you have to set up a test configuration. Here's what you do:
Manually run SAM local (either start-api or invoke) using a command similar to the sample provided on this page. If using start-api, make an API request (e.g. using curl).
In your IDE set up a configuration. In VS code you can use this configuration in the in launch.json file
```js
{
    "version": "0.2.0",
    "configurations": [
        {
            "type": "node",
            "request": "attach",
            "name": "Attach to SAM local",
            "address": "localhost",
            "port": 5858,
            "localRoot": "${workspaceFolder}/lambdas/booking",
            "remoteRoot": "/var/task"
        }
    ]
}
```
The important part is to give the full path to the file containing the handler function isnt 'localRoot'. If you give a partial path or the wrong path the breakpoints will not be hit. The remoteRoot should be sed the /var/task, this is where the code is located in the docker container. When you use this test configuration you will be able to put breakpoint inside lambdas/post-booking/index.js and look at the value of the variables.

For comparison, here is a Test configuration that launches a lab experiment:
```js
{
    "type": "node",
    "request": "launch",
    "name": "Test Lambda functions using SAM Local start-api",
    "program": "${workspaceFolder}/test/testAdapterApi.js"
}
```
When you use this test configuration, you'll be able to put breakpoints in test/testAdapterApi.js but NOT in lambdas/post-booking/index.js because the lambda is running inside a docker container.

Finally if you use this Test configuration:
```js
{
    "type": "node",
    "name": "Test Lambda functions using nodejs",
    "program": "${workspaceFolder}/test/testAdapterLambda.js"
}
```
you will be able to put breakpoints in both test/testAdapterLambda.js AND lambdas/post-booking/index.js because now you are just using pure node, docker is not involved.

### Configuration
If you run the Reuse server locally by using config/environment-variables.json(e.g., by 'sam local invoke' or 'sam local start-api'), you need change configurations in files under config folder in OneMobileNodeUtilityAPI library.


please go to AWS admin console, go to the region you deployed the Reuse server and change parameters in /[SiteName]/ReuseServer/ in the parameter store.
